{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIS 9\n",
    "## Pandas, Data Analysis, Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading\n",
    "<br>Python Data Science Handbook Chapter 3\n",
    "- Introducing Pandas Objects\n",
    "- Data Indexing and Selection\n",
    "- Handling Missing Data, section on NaN\n",
    "- Combining Datasets: Concat and Append, section on concat\n",
    "- Aggregation and Grouping, section on groupby\n",
    "- Vectorized String Operations, up to but not including the Example Recipe Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison of different data storage:\n",
    "- A Python list can store different types of data and can change size, but the flexibility makes indexing and calculation of data in a list slow.\n",
    "- A numpy array can only store only one data type and has fixed size, therefore indexing and calculation of data in a numpy array is very fast.\n",
    "- A pandas data structure can store different types of data, so indexing data is a little slower than numpy but still faster than a list, and when calculations are done with numeric data, they are done using numpy and are very fast. \n",
    "<br>For data analysis purpose, this is best of both worlds! We get some of the flexibility and all the calculation speed.\n",
    "<br><br>A pandas DataFrame (a 2D structure) is the workhorse of data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np   \n",
    "# Pandas doesn't need importing of numpy, this import is for when we need numpy directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas __Series__: 1D sequence of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. A Series is similar to a Python list, with data and indices\n",
    "nums = pd.Series([1,5,2,8,3])\n",
    "print(nums, '\\n')\n",
    "print(nums.values, '\\n')\n",
    "print(nums.index, '\\n')\n",
    "print(nums[0], '\\n')\n",
    "print(nums[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Internally, numeric data are stored in a numpy array\n",
    "nums = pd.Series([0, -2.5, 8, -.7, 3])\n",
    "print(type(nums[0]))\n",
    "# and numpy operations can be used with numeric data\n",
    "np.sum(nums)     \n",
    "\n",
    "# Jupyter Notebook tip:\n",
    "# In Jupyter Notebook, you don't have to use print() if the code in the cell produces \n",
    "# one output, because Jupyter Notebook will automatically print the output.\n",
    "# If the code produces multiple output, then a print() is needed for all output except \n",
    "# the last output, because Jupyter Notebook will only display the last one.\n",
    "\n",
    "# For these exercise notebooks, I use print() for all output except the last one,\n",
    "# or when we need to print text along with the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. A Series is more flexible than a Python list because we can customize the indices.\n",
    "# In this way, a Series behaves similar to a Python dictionary\n",
    "nums = pd.Series([99, 85, 72, 89], index=['quiz1', 'quiz2', 'quiz3', 'quiz4'])\n",
    "print(nums, '\\n')\n",
    "print(\"Quiz 1:\", nums['quiz1'])\n",
    "\n",
    "# Pandas provides an easier way to type when indexing data:\n",
    "print(\"Quiz 1:\", nums.quiz1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. In addition to creating a Series from a Python list, we can create a Series\n",
    "# from a Python dictionary\n",
    "d = {c:ord(c) for c in \"ABCDE\"}\n",
    "letters = pd.Series(d)\n",
    "print(letters.A, '\\n')\n",
    "letters['C':'E']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas __Dataframe__: 2D table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. A DataFrame is a 2D table with rows and columns, similar to a Python list of lists or\n",
    "# a numpy 2D array\n",
    "df = pd.DataFrame([ [90, 92], [73, 82],[79, 80], [97, 95] ])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Just like with Series, we can customize the column indices.\n",
    "# Each columnn of a DataFrame is a Series.\n",
    "df = pd.DataFrame(columns=[\"quiz1\", \"quiz2\"],\n",
    "                  data=[ [90, 92], [73, 82],[79, 80], [97, 95] ])\n",
    "\n",
    "print(df, '\\n')   # note the difference between Python print vs. Jupyter Notebook print \n",
    "np.median(df.quiz2)\n",
    "\n",
    "# Why do numpy operations naturally work on a column of a DataFrame?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 7. Don't forget that an advantage of a DataFrame is that each column can have its own type \n",
    "# of data\n",
    "df = pd.DataFrame(columns=[\"Names\", \"quiz1\", \"quiz2\"],\n",
    "                  data=[ [\"Fred\",90,92.5], [\"Wilma\",73,82],[\"Barney\",79,80], [\"Betty\",90,95] ])\n",
    "df\n",
    "\n",
    "# Why does quiz2 contain floats while quiz1 contains ints?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Accessing__ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. We've seen the . (dot) notation to index a column:\n",
    "print(df.quiz1, '\\n')\n",
    "\n",
    "# Use .columns with numeric column indices and []\n",
    "print(df.columns[1:3])\n",
    "print(df[df.columns[1:3]], '\\n')\n",
    "# there is no df.rows\n",
    "\n",
    "# Use .loc for row and column indices:\n",
    "print(df.loc[1:3], '\\n')     # Note the inclusive ending for .loc\n",
    "print(df.loc[:,['quiz1','quiz2']],'\\n')\n",
    "print(df.loc[2,['quiz1']],'\\n')\n",
    "\n",
    "# When accessing a single element, it's faster to use .at:\n",
    "print(df.at[2,'quiz1'],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. To access data with a specific value or range of values in a column:\n",
    "print(df[df.quiz1 == 90], '\\n')\n",
    "print(df[df.quiz2 < 90],'\\n')\n",
    "print(df[df.Names == \"Betty\"],'\\n')\n",
    "\n",
    "# Write 1 print statement to print the names of students with quiz2 score greater than 90 ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Reading__ from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. If the file is a column of data, it will be read into a Series\n",
    "quiz1 = pd.read_csv(\"quiz_scores.csv\")\n",
    "print(quiz1, '\\n')\n",
    "\n",
    "# Note: for data analysis, all scores in the examples in this notebook are out of 50.\n",
    "\n",
    "# If the file is a csv file with rows and columns, it will be read into a DataFrame\n",
    "gradebook = pd.read_csv(\"scores.csv\")\n",
    "print(gradebook, '\\n')\n",
    "\n",
    "gradebook = pd.read_csv(\"scores.csv\", index_col='Student')\n",
    "print(gradebook, '\\n')\n",
    "\n",
    "gradebook = pd.read_csv(\"scores.csv\", header=0, names=[\"name\",\"q1\",\"midt\",\"q2\",\"final\"])\n",
    "print(gradebook,'\\n')\n",
    "\n",
    "gradebook = pd.read_csv(\"scores.csv\", header=0, names=[\"q1\",\"midt\",\"q2\",\"final\"])\n",
    "print(gradebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. We can also read from Excel files (among many other common types: HTML, JSON, SQL, etc.)\n",
    "gradebook = pd.read_excel(\"scores.xlsx\", index_col='Student')\n",
    "gradebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. From the gradebook in the cell above:\n",
    "# print the data for the student named Doc?\n",
    "\n",
    "# print Dopey's quiz1 and quiz2?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show __attributes__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#13. \n",
    "print(gradebook.index)          # row indices or labels\n",
    "print(gradebook.columns, '\\n')  # column indices or labels\n",
    "print(len(gradebook), '\\n')\n",
    "print(gradebook.head(), '\\n')\n",
    "gradebook.tail(3)\n",
    "\n",
    "# what do head() and tail() do?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic __statistics__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. We can get all the basic stats in one method\n",
    "gradebook.describe()\n",
    "\n",
    "# Review statistics and data analysis:\n",
    "# You are the teacher for this class, and as a good teacher, you want to improve your \n",
    "# class material.\n",
    "# Run the cell so you can see the statistics for the exams: quiz1, midterm, quiz2, final\n",
    "# Using the statistics, you will need to improve the class material for which exam?\n",
    "# Explain your choice by citing specific statistic values to explain how they show the \n",
    "# the need to improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 15. To get a specific statistic for a specific column, we use numpy\n",
    "print(np.median(gradebook.quiz1))\n",
    "print(np.mean(gradebook.quiz2), '\\n')\n",
    "# or pandas\n",
    "print(gradebook.quiz2.mean(), '\\n')\n",
    "\n",
    "# Can also get all statistics of one column\n",
    "gradebook.quiz2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. Show a sample of students who earned more than 90% and more than 80% in their final\n",
    "print(gradebook[gradebook.final > 50*.9], '\\n')\n",
    "print(gradebook[gradebook.final > 50*.8], '\\n')\n",
    "\n",
    "# Show the number of students who earned more than 90% and more than 80% in their final?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Basic __Calculations__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. Assume the midterm and final are each worth 30% of the grade, and quiz1 and quiz2 \n",
    "# are each worth 20% of the grade. \n",
    "# (This means 60% of the grade comes from the midterm and final, and 40% of the grade \n",
    "# comes from the quizzes)\n",
    "# We want to calculate the weighted average of the exams. \n",
    "# and we want the score to be out of 100 to make it easier to see the percentage.\n",
    "wtAvg=(.2 * gradebook.quiz1 + .2 * gradebook.quiz2 + \n",
    "       .3 * gradebook.midterm + .3 * gradebook.final)\n",
    "print(wtAvg)\n",
    "\n",
    "# Show the wtAvg as a percentage?\n",
    "# Recall that the raw scores are out of 50.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18. Sort by a column\n",
    "print(gradebook, '\\n')\n",
    "print(gradebook.sort_values(by=\"quiz1\"), '\\n')\n",
    "print(gradebook.sort_values(by=\"quiz1\", ascending=False), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19. Remove rows\n",
    "gradebook = pd.read_excel(\"scores.xlsx\", index_col='Student')\n",
    "print(gradebook,'\\n')\n",
    "print(gradebook.drop([\"Sneezy\",\"Happy\"]),'\\n')\n",
    "print(gradebook,'\\n')\n",
    "\n",
    "gradebook.drop([\"Sneezy\",\"Happy\"], inplace=True)\n",
    "print(gradebook,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20. Remove columns\n",
    "gradebook.drop(columns=['quiz2'], inplace=True)\n",
    "gradebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21. Adding from another DataFrame\n",
    "gradebook = pd.read_excel(\"scores.xlsx\", index_col='Student')\n",
    "stInfo = pd.read_excel(\"ids.xlsx\", index_col='Student')\n",
    "data = pd.concat([stInfo, gradebook], axis=1)\n",
    "data\n",
    "#data = pd.concat([stInfo, gradebook])  # axis=0\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 22. Append data \n",
    "# append another DataFrame\n",
    "gradebook = pd.read_excel(\"scores.xlsx\")\n",
    "newrow = pd.DataFrame(columns=['Student','quiz1','midterm','quiz2','final'],\n",
    "                      data=[ [\"New Kid\",30,30,30,30] ])\n",
    "print(newrow)\n",
    "gradebook = gradebook.append(newrow, ignore_index=True)\n",
    "gradebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append a dictionary\n",
    "gradebook = pd.read_excel(\"scores.xlsx\")\n",
    "d = dict(zip(['Student','quiz1','midterm','quiz2','final'],[\"New Kid\",30,30,30,30]))\n",
    "print(d)\n",
    "gradebook = gradebook.append(d, ignore_index=True)\n",
    "gradebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__groupby__ for data aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23\n",
    "print(data.groupby(\"year\").mean(), '\\n')\n",
    "\n",
    "# The above output shows the mean of the id's, which doesn't make sense.\n",
    "# Show the mean of the exams only?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data or __NaN__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24. When data is read in to a DataFrame and some values are missing, the missing values \n",
    "# appear as NaN values in the DataFrame. NaN is the IEEE defined value for Not a Number.\n",
    "data = pd.read_csv(\"classes.csv\")   # empty field in CSV file\n",
    "print(data, '\\n')\n",
    "\n",
    "# remove data records (rows) with NaN\n",
    "cleanedData = data.dropna()\n",
    "print(cleanedData, '\\n')\n",
    "\n",
    "# replace NaN with some default value\n",
    "subbedData = data.fillna(0)\n",
    "print(subbedData, '\\n')\n",
    "\n",
    "# check for NaN in the DataFrame\n",
    "data[data.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25. NaN with numpy\n",
    "print(np.median(data['Number of Students']))\n",
    "print(np.median(cleanedData['Number of Students']), '\\n')\n",
    "\n",
    "# NaN with pandas\n",
    "print(data['Number of Students'].median())\n",
    "data['Number of Students'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change column labels: __string vectorization__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 26. As seen from the cell above, it's more convenient to have a shorter column label.\n",
    "# Simplify the data.columns (column labels) so it's easier to type.\n",
    "# a. change the column labels so they're all lowercase\n",
    "data.columns = data.columns.str.lower()\n",
    "\n",
    "# b. change column labels to 1 word: class, days, time, units, students ?\n",
    "# You'll need to do the reading for this answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 27. the location is always De Anza, which doesn't give us any info.\n",
    "# remove location column ?\n",
    "data = data.drop(columns=['location'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
