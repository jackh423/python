{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIS 9\n",
    "## Introduction to Machine Learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading\n",
    "<br>The Data Science Handbook, Chapter 5:\n",
    "- What is machine learning\n",
    "- Introducing Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning (ML) is a field that works with algorithms that can \"learn,\" or improve themselves, due to their experience with input data and not due to a programmer writing a better algorithm. As the algorithm proceses more and more input data, it modifies itself to be more correct when encountering new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning can be divided into 3 main categories: supervised learning, unsupervised learning, and reinforcement learning. Even though there is a wide spectrum of machine learning algorithms, in general most algorithms can be classified in one of these three categories. The following discusses each type of learning, in order from simple to more complex.\n",
    "\n",
    "In __supervised learning__ there are: \n",
    "- a known set of input called _features_. The standard variable name for the features is X.\n",
    "- a known set of output called _labels_. The standard variable name for the labels is y.\n",
    "\n",
    "The goal of the algorithm is to learn the mapping function that maps the input to the output. So that when given new samples of X features, the machine can correctly predict the corresponding y labels.\n",
    "\n",
    "Examples of common supervised learning applications:\n",
    "- Given features of a car, a truck, a bus, the algorithm can determine that a new vehicle is a truck. This is known as a _classification_ problem.\n",
    "- Given features of popular and unpopular movies, the algorithm can predict that a new movie is likely to be popular. This is known as a _regression_ problem.\n",
    "\n",
    "In __unsupervised learning__ there are:\n",
    "- a set of features X \n",
    "- no corresponding labels y\n",
    "\n",
    "The goal of the algorithm is to find previously unknown patterns in X. These patterns often are meaningful clusters of similar samples of X, which can show the categories or attributes intrinsic to the data. So that when given new samples of X, the machine can correctly identify the data.\n",
    "\n",
    "An example of a common unsupervised learning application:\n",
    "<br>Given features (such as buying and browsing habits) of customers, the algorithm can group customers with similar tendencies together for marketing purpose. This is known as a _clustering_ problem.\n",
    "\n",
    "In __reinforcement learning__ there are:\n",
    "- an initial state as input\n",
    "- criticism or reward\n",
    "\n",
    "The algorithm is given an initial state but not given any training data or features X. The algorithm iteratively explores the solution space, and when it reaches a conclusion it receives either criticism or reward (a weighted score). Based on this score, the algorithm continues to improve, and the best solution is the one with the most reward.\n",
    "\n",
    "Examples of common reinforcement learning applications:\n",
    "- An algorithm playing a complicated game such as chess. The initial state is the starting state of the game and a set of rules. The algorithm explores the solution space, which is dependent on the other player's moves, and use the learned cricism or reward to try to win the game.\n",
    "- A robot that navigates terrains to perform a task. The initial state comes from the environment around the robot, which is changeable. The algorithm uses its learned cricism or reward to respond to the changing environment and perform the task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Given the ice cream sales and temperature problem that was discussed in module 2 (matplotlib) exercise, in which the algorithm can advise the ice cream truck owner how much ice cream to store in the truck for selling, based on the week's temperature. What type of learning algorithm would it be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is supervised learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main steps of machine learning are:\n",
    "- Gather and prepare the training data\n",
    "- Choose an algorithm\n",
    "- Train the algorithm\n",
    "- Test the algorithm with new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate these steps, we start with a simple supervised learning example. The algorithm will learn some basic differences between an apple and an orange, and then identify if a new fruit is an apple or an orange."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1a. Gather data\n",
    "<br>Write code to read the fruits.xlsx file into a DataFrame, then print the DataFrame to view the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Weight  Texture   Fruit\n",
      "0     143    0.870  Orange\n",
      "1      90    0.200   Apple\n",
      "2      82    0.125   Apple\n",
      "3      93    0.120   Apple\n",
      "4      87    0.140   Apple\n",
      "5      90    0.880  Orange\n",
      "6     123    0.890  Orange\n",
      "7     116    0.900  Orange\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "fruitsDF = pd.read_excel(\"fruits.xlsx\")\n",
    "print(fruitsDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1b. Prepare data\n",
    "<br>The fruit _features_ are the weight (in grams) and the skin texture (a smooth texture is closer to 0.0, the rough texture is closer to 1.0). \n",
    "<br>The fruit _labels_ are the fruit names: apple or orange\n",
    "<br>Write code to separate the DataFrame into:\n",
    "- a DataFrame named _features_ that has the weight and texture\n",
    "- a Series named _labels_ that has the fruit names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Weight  Texture\n",
      "0     143    0.870\n",
      "1      90    0.200\n",
      "2      82    0.125\n",
      "3      93    0.120\n",
      "4      87    0.140\n",
      "5      90    0.880\n",
      "6     123    0.890\n",
      "7     116    0.900 \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "0    Orange\n",
      "1     Apple\n",
      "2     Apple\n",
      "3     Apple\n",
      "4     Apple\n",
      "5    Orange\n",
      "6    Orange\n",
      "7    Orange\n",
      "Name: Fruit, dtype: object \n",
      "\n",
      "<class 'pandas.core.series.Series'> \n",
      "\n",
      "   Weight  Texture\n",
      "0     143    0.870\n",
      "1      90    0.200\n",
      "2      82    0.125\n",
      "3      93    0.120\n",
      "4      87    0.140\n",
      "5      90    0.880\n",
      "6     123    0.890\n",
      "7     116    0.900\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "\n",
      "0    Orange\n",
      "1     Apple\n",
      "2     Apple\n",
      "3     Apple\n",
      "4     Apple\n",
      "5    Orange\n",
      "6    Orange\n",
      "7    Orange\n",
      "Name: Fruit, dtype: object\n",
      "\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# Method 1\n",
    "features = fruitsDF[[\"Weight\", \"Texture\"]].copy()\n",
    "labels = pd.Series(fruitsDF.Fruit)\n",
    "print(features, \"\\n\")\n",
    "print(type(features), \"\\n\")\n",
    "print(labels, \"\\n\")\n",
    "print(type(labels), \"\\n\")\n",
    "\n",
    "\n",
    "# Second Method\n",
    "features = fruitsDF.loc[:, [\"Weight\",\"Texture\"]]\n",
    "print(features)\n",
    "print()\n",
    "print(type(features))\n",
    "print()\n",
    "labels = pd.Series(fruitsDF[\"Fruit\"])\n",
    "print(labels)\n",
    "print()\n",
    "print(type(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Choose an algorithm\n",
    "<br>This is often the most difficult step: finding the correct algorithm to do the job.\n",
    "Scikit-learn has a diagram for some of the common algorithms: https://scikit-learn.org/stable/tutorial/machine_learning_map/ and the steps to determine which algorithm or _estimator_ to try.\n",
    "\n",
    "For this example, since the algorithm needs to decide or classify if a fruit is an apple or an orage, the algorithm is called a _classifier_. \n",
    "<br>The classifier we'll use is a decision tree. A decision tree is like the Scikit-learn diagram above. In a decision tree the path is continuously split according to each feature. The algorithm makes a decision when it reaches the end of a path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Train the classifier\n",
    "<br>In Scikit-learn, the classifier is trained with the _fit_ method. The input to the fit method, the features and labels, are called the _training data_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = classifier.fit(features, labels)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Test the classifier with new data\n",
    "<br>After training, the classifier is given test data with the _predict_ method, and we can observe the output of the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classifier.predict([[85, 0.29]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second example is a more substantial example of supervised learning, it introduces a few more classifiers and show some common steps that are used in ML. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5a. Gather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-learn has many sample datasets available. We will use the wine dataset is an example.\n",
    "wine = load_wine()\n",
    "\n",
    "# Let's take a look at the general format of the sample datasets.\n",
    "print(type(wine))\n",
    "print(\"keys:\\n\", wine.keys())  # components of dataset\n",
    "print(\"data:\\n\", wine.data, type(wine.data), wine.data.shape)  # features\n",
    "print(\"target:\\n\", wine.target, type(wine.target), wine.target.shape)  # labels\n",
    "print(\"frame:\\n\", wine.frame, type(wine.frame))\n",
    "print(\"feature_name:\\n\", wine.feature_names, type(wine.feature_names))  # feature description\n",
    "print(\"target_name:\\n\", wine.target_names, type(wine.target_names), wine.target_names.shape) # label description\n",
    "#print(\"description:\\n\", wine.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5b. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find X\n",
    "X = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "X.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find y\n",
    "y = pd.Series(wine.target)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the X and y data into 2 parts: training data and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Choose a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We try a few common classifiers to see which one works best\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    GaussianNB()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Train and then test the classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through each classifier\n",
    "for classifier in classifiers:\n",
    "    # train the classifier\n",
    "    classifier.fit(X_train, y_train)  \n",
    "    # test the trained classifier\n",
    "    y_output = classifier.predict(X_test)\n",
    "    # compare the predicted output with the actual output\n",
    "    print(classifier)\n",
    "    print(f\"score: {f1_score(y_test, y_output, average='weighted'):.3f}\")\n",
    "    \n",
    "# the f1 score shows how close the classifier output is to the actual label. \n",
    "# A score of 1.0 is a perfect match, a score of 0.0 is no match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which classifier performs best for the wine dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 1 4.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "A = np.arange(1,16)\n",
    "print(A.max(), A.min(), np.percentile(A,25)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
